<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Fine Tuning – STRAT 490R – Building Strategic AI Solutions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./07-agents.html" rel="next">
<link href="./05-retrieval-augmented-generation.html" rel="prev">
<link href="./images/strategic-ai-favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5fd9db47a040b21ac2cac9a0b3b722ba.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="mermaid-theme" content="neutral">
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-foundations.html">Topics</a></li><li class="breadcrumb-item"><a href="./06-fine-tuning.html"><span class="chapter-title">Fine Tuning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">STRAT 490R – Building Strategic AI Solutions</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Syllabus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-schedule.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-assignments.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Assignments Overview</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-foundations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Foundations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-prompt-engineering.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Prompt Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-streamlit-ui.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Streamlit UI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-retrieval-augmented-generation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Retrieval Augmented Generation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-fine-tuning.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Fine Tuning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-agents.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Agents</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-evaluation-and-tooling.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Evaluation And Tooling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-business-strategy.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Business Strategy</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./90-resources.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./98-faq.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">FAQ</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99-references.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-to-model-fine-tuning" id="toc-introduction-to-model-fine-tuning" class="nav-link active" data-scroll-target="#introduction-to-model-fine-tuning">Introduction to Model Fine-Tuning</a>
  <ul class="collapse">
  <li><a href="#what-is-fine-tuning" id="toc-what-is-fine-tuning" class="nav-link" data-scroll-target="#what-is-fine-tuning">What is Fine-Tuning?</a></li>
  <li><a href="#benefits-and-uses-of-fine-tuning" id="toc-benefits-and-uses-of-fine-tuning" class="nav-link" data-scroll-target="#benefits-and-uses-of-fine-tuning">Benefits and Uses of Fine-Tuning</a></li>
  <li><a href="#how-fine-tuning-works-a-roadmap" id="toc-how-fine-tuning-works-a-roadmap" class="nav-link" data-scroll-target="#how-fine-tuning-works-a-roadmap">How Fine-Tuning Works: A Roadmap</a></li>
  </ul></li>
  <li><a href="#choose-a-base-model" id="toc-choose-a-base-model" class="nav-link" data-scroll-target="#choose-a-base-model">1) Choose a Base Model</a></li>
  <li><a href="#data-preparation-for-fine-tuning" id="toc-data-preparation-for-fine-tuning" class="nav-link" data-scroll-target="#data-preparation-for-fine-tuning">2) Data Preparation for Fine-Tuning</a></li>
  <li><a href="#techniques-for-fine-tuning" id="toc-techniques-for-fine-tuning" class="nav-link" data-scroll-target="#techniques-for-fine-tuning">3) Techniques for Fine-Tuning</a>
  <ul class="collapse">
  <li><a href="#parameter-efficient-fine-tuning-peft" id="toc-parameter-efficient-fine-tuning-peft" class="nav-link" data-scroll-target="#parameter-efficient-fine-tuning-peft">Parameter Efficient Fine-Tuning (PEFT)</a></li>
  <li><a href="#preference-tuning-and-dpo" id="toc-preference-tuning-and-dpo" class="nav-link" data-scroll-target="#preference-tuning-and-dpo">Preference Tuning and DPO</a></li>
  </ul></li>
  <li><a href="#training-arguments-and-hyperparameter-optimization" id="toc-training-arguments-and-hyperparameter-optimization" class="nav-link" data-scroll-target="#training-arguments-and-hyperparameter-optimization">4) Training Arguments and Hyperparameter Optimization</a>
  <ul class="collapse">
  <li><a href="#key-hyperparameters-and-what-they-do" id="toc-key-hyperparameters-and-what-they-do" class="nav-link" data-scroll-target="#key-hyperparameters-and-what-they-do">Key Hyperparameters and What They Do</a></li>
  <li><a href="#a-few-examples" id="toc-a-few-examples" class="nav-link" data-scroll-target="#a-few-examples">A Few Examples</a></li>
  <li><a href="#choosing-good-defaults" id="toc-choosing-good-defaults" class="nav-link" data-scroll-target="#choosing-good-defaults">Choosing Good Defaults</a></li>
  <li><a href="#summary-2" id="toc-summary-2" class="nav-link" data-scroll-target="#summary-2">Summary</a></li>
  </ul></li>
  <li><a href="#evaluating-fine-tuned-models" id="toc-evaluating-fine-tuned-models" class="nav-link" data-scroll-target="#evaluating-fine-tuned-models">5) Evaluating Fine-Tuned Models</a></li>
  <li><a href="#challenges-and-limitations-of-fine-tuning" id="toc-challenges-and-limitations-of-fine-tuning" class="nav-link" data-scroll-target="#challenges-and-limitations-of-fine-tuning">Challenges and Limitations of Fine-Tuning</a></li>
  <li><a href="#case-studies-of-successful-fine-tuning" id="toc-case-studies-of-successful-fine-tuning" class="nav-link" data-scroll-target="#case-studies-of-successful-fine-tuning">Case Studies of Successful Fine-Tuning</a>
  <ul class="collapse">
  <li><a href="#case-study-1-fine-tuning-bert-for-sentiment-analysis" id="toc-case-study-1-fine-tuning-bert-for-sentiment-analysis" class="nav-link" data-scroll-target="#case-study-1-fine-tuning-bert-for-sentiment-analysis">Case Study 1: Fine-Tuning BERT for Sentiment Analysis</a></li>
  <li><a href="#case-study-2-fine-tuning-gpt-3-for-custom-text-generation" id="toc-case-study-2-fine-tuning-gpt-3-for-custom-text-generation" class="nav-link" data-scroll-target="#case-study-2-fine-tuning-gpt-3-for-custom-text-generation">Case Study 2: Fine-Tuning GPT-3 for Custom Text Generation</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  <li><a href="#future-trends-in-fine-tuning" id="toc-future-trends-in-fine-tuning" class="nav-link" data-scroll-target="#future-trends-in-fine-tuning">Future Trends in Fine-Tuning</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02-foundations.html">Topics</a></li><li class="breadcrumb-item"><a href="./06-fine-tuning.html"><span class="chapter-title">Fine Tuning</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Fine Tuning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction-to-model-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-model-fine-tuning">Introduction to Model Fine-Tuning</h2>
<section id="what-is-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="what-is-fine-tuning">What is Fine-Tuning?</h3>
<p><strong>Fine-tuning</strong> is the process of taking a pre-trained AI model (one already trained on broad data) and training it further on a smaller, task-specific dataset to adapt it to a particular use case. Instead of training a large language model (LLM) from scratch (which would require billions of tokens and enormous compute), fine-tuning starts with an existing model that has general knowledge and calibrates it to perform optimally for your needs.</p>
<p><strong>Pre-training</strong> (or base training) refers to the original training of a model on a very large corpus of general data (e.g.&nbsp;crawling the web, books, Wikipedia). This teaches the model broad patterns of language and world knowledge but not any one task in particular. Fine-tuning, in contrast, begins with those pre-trained weights and further trains the model on a much smaller, specialized dataset. Pre-training starts from scratch (random weights) and requires vast data and time, whereas fine-tuning starts from a knowledgeable model and is relatively fast and cost-effective.</p>
<div class="cell" data-eval="true" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR
    A(["Raw Text Data 
    (Web, Books, Wikipedia)"]) -.-&gt; B{{Pre-training}}
    B --&gt; C((Base LLM))
    D(["Domain-Specific Dataset"]) -.-&gt; E{{Fine-tuning}}
    C --&gt; E
    E --&gt; F((Fine-Tuned LLM))

    %% Style assignments
    class A,D Sky;
    class B,E Ash;
    class C,F Aqua;

    %% Style definitions
    classDef Sky stroke-width:1px, stroke:#374D7C, fill:#E2EBFF, color:#374D7C;
    classDef Ash stroke-width:1px, stroke:#999999, fill:#EEEEEE, color:#000000;
    classDef Aqua stroke-width:1px, stroke:#46EDC8, fill:#DEFFF8, color:#378E7A;
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>A useful analogy is training a college graduate for a new job. Pre-training is like sending someone through years of general education: they learn how to think, write, and analyze problems across many subjects. They graduate with broad knowledge but no experience in your specific company or domain.</p>
<p>Fine-tuning is like giving that graduate a few weeks of onboarding and role-specific training. You teach them your tools, your customers, your terminology. You don’t need to re-teach the fundamentals—they already have them. You’re simply refining their knowledge so they can do your job well.</p>
<hr>
<p><strong>Check Your Understanding</strong></p>
<div class="callout callout-style-default callout-tip callout-titled" title="What does it mean to train?">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What does it mean to train?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To train a language model means to adjust the internal parameters (called weights) of a neural network so it improves at predicting or generating language.</p>
<p>Instead of just <strong>telling</strong> the model what to do with a prompt, training actually <strong>shows</strong> the model what to do—by providing many examples of input and output pairs. Training bakes those patterns into the model itself. After training, the model doesn’t just follow instructions temporarily; it has learned new behavior permanently.</p>
<p>This is typically done using <strong>gradient descent</strong>, a process that compares the model’s prediction to the correct output, calculates the <strong>loss</strong> (error), and then updates the weights to reduce that loss in future predictions.</p>
<blockquote class="blockquote">
<p><strong>Example:</strong><br>
If the model sees the prompt *“The capital of France is ___“* and predicts <em>“Berlin”</em>, the loss will be high. The model then adjusts its internal weights to make <em>“Paris”</em> more likely next time.</p>
</blockquote>
<p>We will discuss training loss further in a later section when we prepare to fine-tune our own model.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="What are the key differences between pretraining and fine-tuning?">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What are the key differences between pretraining and fine-tuning?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 40%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Pretraining</th>
<th>Fine-Tuning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Starting Point</strong></td>
<td>From scratch (random weights)</td>
<td>From a pretrained model (existing weights)</td>
</tr>
<tr class="even">
<td><strong>Dataset Size</strong></td>
<td>Massive (web-scale data)</td>
<td>Small and domain/task-specific</td>
</tr>
<tr class="odd">
<td><strong>Objective</strong></td>
<td>Learn general language/world patterns</td>
<td>Specialize for a narrow use case</td>
</tr>
<tr class="even">
<td><strong>Compute Cost</strong></td>
<td>Extremely high (weeks of GPU time)</td>
<td>Relatively low (hours or days)</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p><strong>Remember:</strong> Pretraining is about learning <em>language</em>. Fine-tuning is about learning <em>your task</em>.</p>
</blockquote>
</div>
</div>
</div>
</section>
<section id="benefits-and-uses-of-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="benefits-and-uses-of-fine-tuning">Benefits and Uses of Fine-Tuning</h3>
<p>Fine-tuning is a powerful tool for making large language models more useful, focused, and efficient. It allows organizations to adapt general-purpose models to their specific needs, tasks, and data. Below are four of the most important reasons organizations choose to fine-tune their models:</p>
<p><strong>1. Cost-Effective and Compute-Efficient</strong></p>
<p>One of the primary benefits of fine-tuning is the significant reduction in both <strong>computational resources</strong> and <strong>ongoing API costs</strong>. Training a model from scratch requires vast amounts of data and compute, which can be prohibitively expensive. But even using hosted APIs from providers like OpenAI or Anthropic can become expensive at scale—especially if your application makes frequent or complex calls.</p>
<p>Fine-tuning an <strong>open-source model</strong> gives you long-term cost control by allowing you to host the model yourself and avoid usage-based API billing. By starting with a pretrained model—which has already learned general patterns and language structure—you can adapt it to your specific needs using relatively little data and compute.</p>
<p>This is especially valuable for startups, research teams, or smaller organizations looking to deploy models efficiently without relying on expensive external infrastructure.</p>
<p><strong>2. Domain Adaptation and Task Specialization</strong></p>
<p>Pretrained models are generalists: they understand language broadly, but they’re not experts in your specific domain. Fine-tuning allows you to specialize a model for a particular task (e.g., summarization, classification) or domain (e.g., legal, medical, education).</p>
<p>By training on examples from your target use case, the model learns domain-specific terminology, writing styles, and reasoning patterns. For example, a model fine-tuned on customer reviews can learn to detect nuanced sentiment more effectively than a generic model.</p>
<p>In many cases, a <strong>small fine-tuned model can outperform a much larger generalist LLM</strong> on a specific task. This results in faster inference, lower latency, and more relevant responses—even with far fewer parameters.</p>
<p><strong>3. Control Over Behavior</strong></p>
<p>Prompt engineering and retrieval techniques can guide what a model talks about, but they don’t fundamentally change how it reasons, responds, or formats answers.</p>
<p>Fine-tuning gives you much greater control over:</p>
<ul>
<li>The <strong>tone and style</strong> of responses (e.g., friendly, formal, concise)<br>
</li>
<li>The model’s <strong>workflow and logic</strong>, such as following step-by-step reasoning<br>
</li>
<li>The <strong>consistency</strong> of outputs across prompts and users</li>
</ul>
<p>This is how companies train AI to stay on-brand, follow safety guidelines, or mirror specific writing styles.</p>
<p><strong>4. Privacy and Security</strong></p>
<p>When working with sensitive or proprietary data, fine-tuning provides a way to embed that knowledge into the model without exposing it to external APIs.</p>
<p>Key benefits include:</p>
<ul>
<li><strong>Data remains in-house</strong> — fine-tuning can be done on private infrastructure<br>
</li>
<li><strong>No need to send sensitive context repeatedly</strong> via prompts<br>
</li>
<li><strong>Enables informed generation</strong> using non-public or confidential information</li>
</ul>
<p>This is critical for applications in healthcare, finance, government, and enterprise, where data privacy and compliance are essential.</p>
<hr>
<p><strong>In summary</strong>, fine-tuning is a critical technique for developing strategic AI solutions because it bridges the gap between general-purpose language models and real-world applications. It enables organizations to adapt powerful pretrained models to their specific domains, workflows, and privacy constraints—without the cost of training from scratch. Whether optimizing performance, reducing latency, enforcing brand voice, or securing sensitive data, fine-tuning is how AI becomes truly useful, usable, and aligned with business goals.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Comparison: Prompt Engineering vs RAG vs Fine-Tuning
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<style>
  table.clean-table th,
  table.clean-table td {
    padding: 6px 10px;
    text-align: center;
  }
  table.clean-table th:first-child,
  table.clean-table td:first-child {
    text-align: left;
  }
</style>
<table class="caption-top table">
<colgroup>
<col style="width: 32%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th>Criteria</th>
<th>Prompt Engineering</th>
<th>RAG</th>
<th>Fine-Tuning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Ease of Deployment</td>
<td>High</td>
<td>Medium</td>
<td>Low</td>
</tr>
<tr class="even">
<td>Domain Adaptation</td>
<td>Low</td>
<td>High</td>
<td>High</td>
</tr>
<tr class="odd">
<td>Factual Accuracy</td>
<td>Low</td>
<td>High</td>
<td>Moderate (static)</td>
</tr>
<tr class="even">
<td>Control over Output</td>
<td>Limited</td>
<td>Moderate</td>
<td>High</td>
</tr>
<tr class="odd">
<td>Privacy-Friendly</td>
<td>High</td>
<td>Moderate (depends)</td>
<td>High</td>
</tr>
<tr class="even">
<td>Supports Dynamic Content</td>
<td>Low</td>
<td>High</td>
<td>Low</td>
</tr>
<tr class="odd">
<td>Low Latency / Offline Use</td>
<td>Low</td>
<td>Moderate</td>
<td>High</td>
</tr>
<tr class="even">
<td>Consistency / Repeated Tasks</td>
<td>Low</td>
<td>Medium</td>
<td>High</td>
</tr>
<tr class="odd">
<td>Upfront Effort</td>
<td>Low</td>
<td>Medium</td>
<td>High</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>Use this table to compare the tradeoffs between Prompt Engineering, Retrieval-Augmented Generation (RAG), and Fine-Tuning depending on your use case.</p>
</blockquote>
</div>
</div>
</div>
</section>
<section id="how-fine-tuning-works-a-roadmap" class="level3">
<h3 class="anchored" data-anchor-id="how-fine-tuning-works-a-roadmap">How Fine-Tuning Works: A Roadmap</h3>
<p>In order to fine-tune our own language model, we will walk through the following steps:</p>
<ol type="1">
<li><p><strong>Choose a Base Model</strong><br>
Select a pre-trained model that aligns with your task needs (e.g.&nbsp;LLaMA, Mistral, Falcon).</p></li>
<li><p><strong>Prepare a Specialized Dataset</strong><br>
Gather and format examples specific to your domain or task. The quality of this data will directly shape the model’s behavior.</p></li>
<li><p><strong>Select a Fine-Tuning Strategy</strong><br>
Decide whether to fully fine-tune the model or use a parameter-efficient method like LoRA, QLoRA, or adapters.</p></li>
<li><p><strong>Set Training Arguments (Hyperparameters)</strong><br>
Choose your learning rate, batch size, number of epochs, and other settings that influence how the model learns.</p></li>
<li><p><strong>Train, Iterate, and Evaluate</strong><br>
Begin training, monitor the loss, validate the model, and adjust as needed. Use benchmarks and real-world testing to assess performance.</p></li>
</ol>
<blockquote class="blockquote">
<p>We’ll walk through each of these steps in the sections that follow.</p>
</blockquote>
</section>
</section>
<section id="choose-a-base-model" class="level2">
<h2 class="anchored" data-anchor-id="choose-a-base-model">1) Choose a Base Model</h2>
<p>The first decision in any fine-tuning project is selecting a base model—the pre-trained large language model (LLM) you will adapt for your task. Your choice here impacts everything downstream: performance, cost, deployment complexity, techniques/frameworks, and even data formatting.</p>
<p>A base model is a language model that has already been pre-trained on general-purpose data (e.g.&nbsp;books, web pages, Wikipedia). It has learned the structure of language, grammar, reasoning patterns, and world knowledge—but it’s not yet tailored to your specific use case.</p>
<p>There is no one-size-fits-all answer. Here are the main criteria to guide your decision:</p>
<section id="model-size-number-of-parameters" class="level4">
<h4 class="anchored" data-anchor-id="model-size-number-of-parameters"><strong>Model Size (Number of Parameters)</strong></h4>
<p>Larger models can capture more complex relationships and perform better on a wide range of tasks. But they also require more compute, memory, and fine-tuning time.</p>
<p>Smaller models (1–3B) can fine-tune quickly on consumer hardware. They train faster and are easier to deploy locally. Consider your dataset size, GPU availability, and target use case.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 40%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Model Size</strong></th>
<th><strong>Pros</strong></th>
<th><strong>Cons</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>&lt; 3B parameters</strong></td>
<td>Fast, cheap, runs on small devices</td>
<td>Limited reasoning ability</td>
</tr>
<tr class="even">
<td><strong>7–13B parameters</strong></td>
<td>Strong balance of power &amp; performance</td>
<td>Needs a good GPU for fine-tuning</td>
</tr>
<tr class="odd">
<td><strong>&gt; 30B parameters</strong></td>
<td>State-of-the-art results</td>
<td>Expensive and hard to deploy</td>
</tr>
</tbody>
</table>
</section>
<section id="pre-trained-vs-instruction-tuned" class="level4">
<h4 class="anchored" data-anchor-id="pre-trained-vs-instruction-tuned"><strong>Pre-Trained vs Instruction Tuned</strong></h4>
<p>Base models come in two main types:</p>
<ul>
<li><p>Pre-trained models: models that are trained to predict the next word/token on general text data.</p></li>
<li><p>Instruction-tuned models: pretrained models that have already been finetuned once to follow human instructions (e.g., respond to prompts like a chatbot or assistant).</p></li>
</ul>
<p>Instruction-tuned models are typically the best choice when building on top of a model for a real-world use case like chat, summarization, or customer support. They require less effort and data to fine-tune effectively. Pre-trained models, on the other hand, offer more flexibility but require more work to format data, define tasks, and teach the model how to respond appropriately.</p>
</section>
<section id="licensing-and-commercial-use" class="level4">
<h4 class="anchored" data-anchor-id="licensing-and-commercial-use"><strong>Licensing and Commercial Use</strong></h4>
<p>One of the most overlooked—but critical—factors when selecting a base model is its <strong>license</strong>. Not all open-source models are truly open for commercial use.</p>
<p>Some models, like <strong>Meta’s LLaMA 2</strong>, are released under <strong>non-commercial research licenses</strong>, meaning you can experiment, research, and fine-tune—but you cannot deploy them in a commercial product without explicit permission. On the other hand, models like <strong>Mistral</strong> or <strong>Qwen</strong> use more permissive licenses (e.g.&nbsp;<strong>Apache 2.0</strong>), allowing full commercial use, redistribution, and modification.</p>
<p>Licensing directly affects your go-to-market options:</p>
<ul>
<li>If you’re prototyping an internal tool or doing academic research, a research license may be fine.<br>
</li>
<li>But if you’re building a product, deploying to clients, or embedding the model in commercial software, using a commercially restricted model could put you at <strong>legal risk</strong>.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Always check the model’s license</strong> (on Hugging Face or GitHub) before starting fine-tuning. Legal restrictions can vary by use case and may also apply to derivatives of the model.</p>
</blockquote>
</section>
<section id="model-compatibility-and-alignment" class="level4">
<h4 class="anchored" data-anchor-id="model-compatibility-and-alignment"><strong>Model Compatibility and Alignment</strong></h4>
<p>The base model you choose doesn’t just define its capabilities — it also shapes what your fine-tuning process will look like.</p>
<p>Each model has its own:</p>
<ul>
<li>Tokenizer (how it splits up words into tokens)</li>
<li>Preferred data format (e.g.&nbsp;instruction-output, ChatML, ShareGPT-style)</li>
<li>Supported frameworks (like Hugging Face, LLaMA Factory, or Axolotl)</li>
<li>Compatible techniques (like LoRA, QLoRA, or full fine-tuning)</li>
</ul>
<p>Together, these form a kind of alignment: the better your tools, data, and training method match the structure and expectations of the model, the smoother your fine-tuning process will be—and the better your results.</p>
<blockquote class="blockquote">
<p>Think of it like matching an phone to a charger. Some models “plug in” easily to popular fine-tuning frameworks and formats. Others require adapters or workarounds.</p>
</blockquote>
<p>In the next sections, we’ll walk through how to prepare aligned data for your model and choose the training method that best fits your use case and enhances training speed and efficiency.</p>
</section>
</section>
<section id="data-preparation-for-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation-for-fine-tuning">2) Data Preparation for Fine-Tuning</h2>
<p>Fine-tuning is fundamentally a form of supervised learning—teaching a model by showing it many examples of inputs paired with ideal outputs so it learns to replicate those patterns. This section walks through the three core stages of data preparation: <strong>sourcing</strong>, <strong>cleaning</strong>, and <strong>formatting</strong>.</p>
<hr>
<section id="data-sourcing" class="level4">
<h4 class="anchored" data-anchor-id="data-sourcing"><strong>Data Sourcing</strong></h4>
<p>The first step is identifying where your task-specific data will come from. Common sources include:</p>
<ul>
<li><strong>Internal logs</strong> – e.g., customer support transcripts, chatbot conversations, or form submissions<br>
</li>
<li><strong>Public datasets</strong> – from platforms like <a href="https://huggingface.co/datasets?sort=trending">Hugging Face Datasets</a>, Kaggle, or academic benchmarks<br>
</li>
<li><strong>Manual generation</strong> – examples written or annotated by domain experts<br>
</li>
<li><strong>Synthetic generation</strong> – data generated by a base model and later reviewed or edited for quality</li>
</ul>
<p>Each data source offers trade-offs between <strong>volume</strong>, <strong>quality</strong>, and <strong>domain relevance</strong>.</p>
<blockquote class="blockquote">
<p>Fine-tuning doesn’t require massive datasets. What matters is that each example is correct, relevant, and representative. A few hundred high-quality examples often outperform thousands of noisy ones.</p>
</blockquote>
<hr>
</section>
<section id="data-cleaning" class="level4">
<h4 class="anchored" data-anchor-id="data-cleaning"><strong>Data Cleaning</strong></h4>
<p>Raw examples often need cleaning before they’re ready for training. This step focuses on eliminating noise and inconsistencies. Common cleaning tasks include:</p>
<ul>
<li>Removing incomplete or corrupted entries<br>
</li>
<li>Fixing typos, inconsistent punctuation, or formatting issues<br>
</li>
<li>Standardizing casing, spacing, or syntax<br>
</li>
<li>Removing sensitive or personally identifiable information (PII)</li>
</ul>
<p>Clean data helps ensure the model learns meaningful patterns—not accidental ones.</p>
<blockquote class="blockquote">
<p>The single most important factor in fine-tuning success is data quality. A strong model trained on poor data will still perform poorly.</p>
</blockquote>
<hr>
</section>
<section id="data-formatting" class="level4">
<h4 class="anchored" data-anchor-id="data-formatting"><strong>Data Formatting</strong></h4>
<p>Regardless of the task, all fine-tuning datasets must include:</p>
<blockquote class="blockquote">
<p><strong>A clear prompt (or context) and a desired response.</strong></p>
</blockquote>
<p>However, the <strong>format</strong> of this information depends on the model architecture and training history. For example:</p>
<ul>
<li><strong>Instruction-tuned models</strong> expect fields like <code>instruction</code>, <code>input</code>, and <code>output</code>.</li>
<li><strong>Chat models</strong> expect lists of user/assistant messages.</li>
<li><strong>Base models</strong> expect a simple prompt followed by a response.</li>
</ul>
<p>Data is usually stored in <strong>JSON</strong> or <strong>JSON Lines (JSONL)</strong> formats.</p>
<section id="common-data-format-types" class="level5">
<h5 class="anchored" data-anchor-id="common-data-format-types">Common Data Format Types</h5>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Instruction Format (<code>instruction → input → output</code>)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Best for</strong>: task-specific fine-tuning (e.g., summarization, classification, QA)<br>
<strong>Model types</strong>: FLAN-T5, Alpaca, LLaMA Factory-compatible models</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"instruction"</span><span class="fu">:</span> <span class="st">"Translate this sentence to Spanish."</span><span class="fu">,</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"input"</span><span class="fu">:</span> <span class="st">"How are you?"</span><span class="fu">,</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"output"</span><span class="fu">:</span> <span class="st">"¿Cómo estás?"</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Chat Format (<code>messages</code> list)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Best for</strong>: assistant-style or multi-turn dialogue training<br>
<strong>Model types</strong>: ChatML, OpenChat, LLaMA 2-Chat, Zephyr</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"messages"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span><span class="dt">"role"</span><span class="fu">:</span> <span class="st">"user"</span><span class="fu">,</span> <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"What's 2 + 2?"</span><span class="fu">}</span><span class="ot">,</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span><span class="dt">"role"</span><span class="fu">:</span> <span class="st">"assistant"</span><span class="fu">,</span> <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"2 + 2 equals 4."</span><span class="fu">}</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="ot">]</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prompt-Completion Format (<code>prompt → response</code>)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Best for</strong>: creative writing, open-ended completions<br>
<strong>Model types</strong>: base models, GPT-style architectures</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"prompt"</span><span class="fu">:</span> <span class="st">"Write a tagline for a fitness app:"</span><span class="fu">,</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"response"</span><span class="fu">:</span> <span class="st">"Train smart. Live strong."</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="summary" class="level4">
<h4 class="anchored" data-anchor-id="summary"><strong>Summary</strong></h4>
<p>High-quality fine-tuning is less about <strong>how much</strong> data you have and more about <strong>how useful</strong> each example is.</p>
<blockquote class="blockquote">
<p><strong>Garbage in, garbage out</strong>: If your examples are messy, inconsistent, or unclear, the model will learn those patterns too.</p>
</blockquote>
<p>Always match your data format to the <strong>type of base model</strong> you’re fine-tuning. For example, a chat model expects conversation history, while an instruction-tuned model needs structured tasks and responses.</p>
</section>
</section>
<section id="techniques-for-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="techniques-for-fine-tuning">3) Techniques for Fine-Tuning</h2>
<p>In this section, we’ll explore a curated set of fine-tuning strategies that are shaping the way modern AI solutions are built. While there are many ways to adapt language models, we’ll focus on a small set of methods that are most widely used today. These include parameter-efficient methods (PEFT) such as LoRA and QLoRA. We’ll also touch on preference tuning through Direct Preference Optimization (DPO). Together, these techniques form the essential toolkit for anyone looking to build or deploy customized AI systems.</p>
<section id="parameter-efficient-fine-tuning-peft" class="level3">
<h3 class="anchored" data-anchor-id="parameter-efficient-fine-tuning-peft">Parameter Efficient Fine-Tuning (PEFT)</h3>
<p>When you train a model, you’re adjusting numbers inside it—called weights—so that the model improves its predictions. This usually happens in three steps:</p>
<ol type="1">
<li>The model makes a guess (prediction).</li>
<li>It compares that guess to the correct answer.</li>
<li>It slightly adjusts its weights to reduce the error.</li>
</ol>
<p>In <strong>full fine-tuning</strong>, every single weight in the model can be adjusted. As language models have grown in size—often with billions of parameters—fully fine-tuning all of those weights has become expensive and impractical for most teams. That’s where Parameter-Efficient Fine-Tuning (PEFT) comes in.</p>
<p>Instead of updating the entire model, <strong>PEFT</strong> methods allow you to train a small number of new parameters while keeping the original model frozen. This makes fine-tuning much faster, cheaper, and easier to run on smaller hardware (like consumer GPUs or even Google Colab).</p>
<p>PEFT is an umbrella term for many different techniques. In the next sections, we’ll look at two of the most popular and widely adopted PEFT methods: LoRA and QLoRA</p>
<div id="fig-peft-methods" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-peft-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/peft-methods.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-peft-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.1: Overview of PEFT Methods
</figcaption>
</figure>
</div>
<hr>
<section id="low-rank-adaptation-lora" class="level4">
<h4 class="anchored" data-anchor-id="low-rank-adaptation-lora">Low Rank Adaptation (LoRA)</h4>
<p>LoRA targets the attention layers (a core component of transformer models like GPT or LLaMA). These layers contain big weight matrices, like Wq and Wv, which help the model decide what to pay attention to in a sentence.</p>
<p>Instead of changing these matrices directly, LoRA:</p>
<ul>
<li>Adds two small matrices, called A and B</li>
<li>Multiplies them together to form a low-rank approximation</li>
</ul>
<p>Adds this result to the original frozen matrix during training and inference</p>
</section>
<section id="quantized-low-rank-adaptation-qlora" class="level4">
<h4 class="anchored" data-anchor-id="quantized-low-rank-adaptation-qlora">Quantized Low Rank Adaptation (QLoRA)</h4>
<p>While LoRA dramatically reduces the number of parameters you need to train, the base model (like LLaMA or Mistral) still takes up a lot of memory. That’s where QLoRA (Quantized LoRA) comes in.</p>
<p>QLoRA keeps everything that makes LoRA efficient—but adds quantization to reduce the memory footprint of the base model itself. This makes it possible to fine-tune large models even on laptops or free Colab GPUs.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is Quantization?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Quantization is a way of making a model smaller by storing its weights using <strong>fewer bits</strong>.</p>
<p>Most models use <strong>16-bit or 32-bit floats</strong> to store numbers.<br>
<strong>QLoRA</strong> uses <strong>4-bit integers</strong>, which are much smaller.</p>
<p>This doesn’t change the model’s structure—it just changes how the numbers are stored in memory.</p>
<p>It’s like switching from a high-resolution video to a compressed version that still looks good—but takes up less space.</p>
</div>
</div>
</div>
</section>
</section>
<section id="preference-tuning-and-dpo" class="level3">
<h3 class="anchored" data-anchor-id="preference-tuning-and-dpo">Preference Tuning and DPO</h3>
<p>Most fine-tuning methods rely on giving the model a specific input and the exact output we want it to produce. But sometimes, there’s no single “correct” answer—just answers that are better or worse in the eyes of a human.</p>
<p>For example:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Prompt</th>
<th>Output A</th>
<th>Output B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“What’s a polite way to say no?”</td>
<td>“No, thank you.”</td>
<td>“I’m not doing that.”</td>
</tr>
</tbody>
</table>
<p>Both are technically valid, but one is clearly more helpful and respectful. In these cases, we can use <strong>preference tuning</strong>—a way of training models based on what humans prefer, not just what’s factually correct.</p>
<section id="what-is-preference-tuning" class="level4">
<h4 class="anchored" data-anchor-id="what-is-preference-tuning">What Is Preference Tuning?</h4>
<p><strong>Preference tuning</strong> is about improving a model’s behavior by showing it which responses are preferred in side-by-side comparisons. This is especially useful when:</p>
<ul>
<li>There isn’t one right answer</li>
<li>You want to improve tone, helpfulness, safety, or clarity</li>
<li>You’re aligning the model with human values or user expectations</li>
</ul>
<p>This process is sometimes called <strong>alignment</strong>—making sure the model behaves the way people want.</p>
</section>
<section id="dpo-direct-preference-optimization" class="level4">
<h4 class="anchored" data-anchor-id="dpo-direct-preference-optimization">DPO: Direct Preference Optimization</h4>
<p><strong>Direct Preference Optimization (DPO)</strong> is a newer, simpler approach to preference tuning. Instead of building a complex reward model (as in older methods like PPO), DPO trains the model directly on pairs of outputs where one is preferred over the other.</p>
<section id="how-dpo-works" class="level5">
<h5 class="anchored" data-anchor-id="how-dpo-works">How DPO Works</h5>
<ol type="1">
<li>You collect prompt + response pairs where a human chose one response over another.</li>
<li>The model is trained to assign higher probability to the preferred response.</li>
<li>That’s it—no reward model, no reinforcement learning loop.</li>
</ol>
<blockquote class="blockquote">
<p>Analogy: It’s like teaching someone by showing two possible emails and saying, “This one sounds better.” Over time, they learn the patterns you prefer.</p>
</blockquote>
</section>
</section>
<section id="why-dpo-matters" class="level4">
<h4 class="anchored" data-anchor-id="why-dpo-matters">Why DPO Matters</h4>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Feature</th>
<th>Benefit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Simpler than PPO</td>
<td>No need for reward models or RL algorithms</td>
</tr>
<tr class="even">
<td>Aligns with human values</td>
<td>Trains on what people actually prefer</td>
</tr>
<tr class="odd">
<td>Easy to scale</td>
<td>Works well with modern fine-tuning libraries</td>
</tr>
</tbody>
</table>
</section>
<section id="summary-1" class="level4">
<h4 class="anchored" data-anchor-id="summary-1">Summary</h4>
<ul>
<li>Preference tuning is used when there’s no single right answer, just better ones.</li>
<li>DPO is the most accessible and efficient method for this today.</li>
<li>It’s especially useful for tuning how a chatbot sounds, how safely it answers questions, or how clearly it communicates.</li>
</ul>
</section>
</section>
</section>
<section id="training-arguments-and-hyperparameter-optimization" class="level2">
<h2 class="anchored" data-anchor-id="training-arguments-and-hyperparameter-optimization">4) Training Arguments and Hyperparameter Optimization</h2>
<p>When you fine-tune a language model, you have to decide <strong>how</strong> the training process will work. These decisions are controlled by something called <strong>training arguments</strong> or <strong>hyperparameters</strong>.</p>
<p>Hyperparameters are like <strong>settings or dials</strong> that you tune before training begins. They define how the model learns, how fast it learns, how long it trains, and how much data it sees at a time. Choosing the right hyperparameters is critical to getting good results.</p>
<section id="key-hyperparameters-and-what-they-do" class="level3">
<h3 class="anchored" data-anchor-id="key-hyperparameters-and-what-they-do">Key Hyperparameters and What They Do</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 35%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th>Hyperparameter</th>
<th>What It Controls</th>
<th>Why It Matters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>learning_rate</code></td>
<td>How quickly the model updates its weights</td>
<td>Too high: unstable training; too low: slow or no learning</td>
</tr>
<tr class="even">
<td><code>num_train_epochs</code></td>
<td>How many times the model sees the full dataset</td>
<td>More epochs = more learning, but also risk of overfitting</td>
</tr>
<tr class="odd">
<td><code>per_device_train_batch_size</code></td>
<td>How many examples the model processes at once</td>
<td>Larger batches are faster but use more memory</td>
</tr>
<tr class="even">
<td><code>gradient_accumulation_steps</code></td>
<td>Simulates larger batches over multiple steps</td>
<td>Useful when memory is limited</td>
</tr>
<tr class="odd">
<td><code>cutoff_len</code></td>
<td>Maximum number of tokens per example</td>
<td>Truncates long inputs; controls memory usage</td>
</tr>
<tr class="even">
<td><code>val_size</code></td>
<td>Portion of data used for validation (e.g., 0.1)</td>
<td>Helps track performance on unseen data</td>
</tr>
<tr class="odd">
<td><code>lr_scheduler_type</code></td>
<td>How the learning rate changes over time</td>
<td>Controls whether training slows down or stays steady</td>
</tr>
<tr class="even">
<td><code>max_samples</code></td>
<td>Maximum number of training examples to use</td>
<td>Useful for quick experiments or debugging</td>
</tr>
</tbody>
</table>
</section>
<section id="a-few-examples" class="level3">
<h3 class="anchored" data-anchor-id="a-few-examples">A Few Examples</h3>
<section id="learning-rate" class="level4">
<h4 class="anchored" data-anchor-id="learning-rate">Learning Rate</h4>
<p>The <strong>learning rate</strong> controls how big each step is during training. If it’s too big, the model may bounce around and never converge. If it’s too small, it may take forever to learn—or not learn at all.</p>
<ul>
<li>Typical values: <code>2e-5</code>, <code>5e-5</code>, <code>1e-4</code></li>
<li>For LoRA or QLoRA, <code>2e-4</code> is a good starting point</li>
</ul>
</section>
<section id="batch-size-and-gradient-accumulation" class="level4">
<h4 class="anchored" data-anchor-id="batch-size-and-gradient-accumulation">Batch Size and Gradient Accumulation</h4>
<p>If your GPU can only fit 2 examples at a time (<code>batch_size=2</code>), but you want to simulate a batch size of 8, you can use:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>per_device_train_batch_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>gradient_accumulation_steps <span class="op">=</span> <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This tells the model to accumulate gradients for 4 steps before updating weights—just like having a batch of 8.</p>
</section>
</section>
<section id="choosing-good-defaults" class="level3">
<h3 class="anchored" data-anchor-id="choosing-good-defaults">Choosing Good Defaults</h3>
<p>If you’re just getting started, here’s a simple configuration that works well for small LoRA fine-tuning:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">learning_rate</span><span class="kw">:</span><span class="at"> </span><span class="fl">2e-4</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">num_train_epochs</span><span class="kw">:</span><span class="at"> </span><span class="dv">3</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">per_device_train_batch_size</span><span class="kw">:</span><span class="at"> </span><span class="dv">2</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">gradient_accumulation_steps</span><span class="kw">:</span><span class="at"> </span><span class="dv">4</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cutoff_len</span><span class="kw">:</span><span class="at"> </span><span class="dv">512</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="fu">val_size</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.1</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lr_scheduler_type</span><span class="kw">:</span><span class="at"> cosine</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="fu">max_samples</span><span class="kw">:</span><span class="at"> </span><span class="dv">10000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This setup is designed to balance learning quality with resource efficiency.</p>
</section>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<ul>
<li>Hyperparameters are not learned—they’re chosen by you.</li>
<li>The right values depend on your model, dataset size, hardware, and goals.</li>
<li>You don’t have to guess—start with reasonable defaults and adjust based on the results.</li>
</ul>
<p>Hyperparameter optimization is a critical step in the process of fine-tuning machine learning models. While model parameters are learned from the data during training, hyperparameters are set before the learning process begins and control the behavior of the training algorithm. Examples of hyperparameters include learning rate, batch size, number of epochs, and architecture-specific settings like the number of layers in a neural network.</p>
<p>Choosing the right hyperparameters can significantly affect the performance of a model. Poorly chosen hyperparameters can lead to underfitting, where the model fails to capture the underlying trends in the data, or overfitting, where the model captures noise instead of the signal. Thus, hyperparameter optimization involves systematically searching for the best set of hyperparameters that minimize a predefined loss function on a validation set.</p>
<p>There are several techniques for hyperparameter optimization, including grid search, random search, and more advanced methods like Bayesian optimization. Grid search involves specifying a set of possible values for each hyperparameter and evaluating every possible combination. While exhaustive, this method can be computationally expensive, especially with a large number of hyperparameters. Random search, on the other hand, samples random combinations of hyperparameter values and can be more efficient by covering the hyperparameter space more broadly.</p>
<p>In the code example above, we use GridSearchCV from the scikit-learn library to perform grid search on a RandomForestClassifier. We define a parameter grid that specifies the values to be tested for each hyperparameter. GridSearchCV evaluates the model’s performance using cross-validation and selects the hyperparameters that yield the highest accuracy. The <code>best_params_</code> attribute reveals the optimal settings found.</p>
<p>Random search is another popular method for hyperparameter optimization. It randomly selects combinations of hyperparameters to test. This approach can be more efficient than grid search, especially when some hyperparameters have negligible impact on performance or when the search space is large. Random search is often used in conjunction with domain knowledge to set reasonable ranges for hyperparameters.</p>
<p>In this code snippet, we use RandomizedSearchCV to perform random search. We specify a distribution for hyperparameters and set <code>n_iter</code> to control how many different combinations to test. This method is advantageous when computational resources are limited, as it allows for a broad exploration of the hyperparameter space without testing every possible combination.</p>
<p>More sophisticated techniques, such as Bayesian optimization, use probabilistic models to predict the performance of hyperparameter settings and select the most promising options to evaluate next. This method can be more efficient than both grid and random search, as it uses past evaluations to inform future choices, effectively balancing exploration and exploitation.</p>
<p>In conclusion, selecting the right hyperparameter optimization technique depends on various factors, including the complexity of the model, the size of the dataset, and the computational resources available. Understanding the strengths and limitations of each method allows practitioners to make informed decisions and build more effective AI solutions.</p>
</section>
</section>
<section id="evaluating-fine-tuned-models" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-fine-tuned-models">5) Evaluating Fine-Tuned Models</h2>
<p>After fine-tuning a machine learning model, it is crucial to evaluate its performance to ensure that the adjustments have led to improvements. Evaluating fine-tuned models involves several steps, including selecting appropriate evaluation metrics, conducting thorough testing, and analyzing results to make informed decisions about the model’s deployment. This process ensures that the model not only performs well on the training data but also generalizes effectively to unseen data.</p>
<p>The first step is selecting the right evaluation metrics, which depend on the task at hand. For classification tasks, metrics like accuracy, precision, recall, F1-score, and AUC-ROC are commonly used. For regression tasks, metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared are appropriate. It’s important to choose metrics that align with the specific goals of your model, as different metrics can highlight different aspects of performance.</p>
<p>Once the metrics are selected, the next step is to test the model on a validation set that was not used during the training process. This helps assess the model’s ability to generalize. Additionally, performing cross-validation can provide a more reliable estimate of the model’s performance by averaging results over multiple folds. This technique helps mitigate the risk of overfitting, which occurs when a model learns the training data too well but fails to perform on new data.</p>
<p>In addition to traditional metrics, it is beneficial to conduct error analysis to understand where the model performs poorly. This involves examining cases where the model’s predictions differ significantly from the actual outcomes. By identifying patterns in these errors, you can gain insights into potential model improvements or data quality issues. Visual tools such as confusion matrices for classification tasks can be particularly helpful in this analysis.</p>
<p>Finally, it’s important to consider the model’s performance in the context of its deployment environment. This includes evaluating the model’s inference time, resource consumption, and scalability. For instance, a model that performs well in terms of accuracy but requires excessive computational resources may not be suitable for real-time applications. Thus, balancing performance metrics with practical deployment considerations is key to building strategic AI solutions.</p>
</section>
<section id="challenges-and-limitations-of-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="challenges-and-limitations-of-fine-tuning">Challenges and Limitations of Fine-Tuning</h2>
<p>Fine-tuning pre-trained models is a powerful technique that enables the adaptation of general-purpose models to specific tasks. However, it comes with a set of challenges and limitations that practitioners must navigate carefully. Understanding these challenges is crucial for effectively applying fine-tuning techniques in building strategic AI solutions.</p>
<p>One of the primary challenges of fine-tuning is the risk of overfitting. When a model is fine-tuned on a small dataset, it may learn patterns that are specific to the training data but do not generalize well to new, unseen data. This is particularly problematic in domains where labeled data is scarce. To mitigate overfitting, techniques such as data augmentation, dropout, and early stopping can be employed. Data augmentation artificially increases the size of the training dataset by creating modified versions of the existing data, while dropout randomly sets a portion of the neurons to zero during training to prevent co-adaptation.</p>
<p>Another limitation is the computational cost associated with fine-tuning. Pre-trained models, especially those based on deep learning architectures like transformers or convolutional neural networks, can be large and require significant computational resources for training. This can be a barrier for organizations with limited access to high-performance computing resources. Techniques such as model pruning, quantization, and knowledge distillation can help reduce the computational burden by simplifying the model or transferring knowledge to a smaller model.</p>
<p>Fine-tuning also requires careful consideration of the learning rate. If the learning rate is too high, the model may diverge from a good solution; if too low, the model may converge too slowly or get stuck in a local minimum. A common approach is to use a smaller learning rate for the pre-trained layers and a larger one for the newly added layers, as the pre-trained layers likely already contain useful features that should not be disrupted excessively.</p>
<p>Finally, domain shift poses a significant challenge in fine-tuning. The pre-trained model may have been trained on data that is significantly different from the target domain, leading to suboptimal performance. This is especially relevant in fields like medical imaging, where pre-trained models might have been developed on general object datasets but need to be applied to specific medical images. Transfer learning strategies, such as domain adaptation techniques, can help bridge this gap by aligning the feature distributions between the source and target domains.</p>
</section>
<section id="case-studies-of-successful-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="case-studies-of-successful-fine-tuning">Case Studies of Successful Fine-Tuning</h2>
<p>In the previous section, we explored the challenges and limitations associated with fine-tuning AI models, such as overfitting, data scarcity, and computational costs. In this section, we will delve into case studies that highlight successful applications of fine-tuning techniques across various domains. These examples will illustrate how strategic fine-tuning can significantly enhance model performance, adapt solutions to specific tasks, and overcome some of the challenges previously discussed.</p>
<section id="case-study-1-fine-tuning-bert-for-sentiment-analysis" class="level3">
<h3 class="anchored" data-anchor-id="case-study-1-fine-tuning-bert-for-sentiment-analysis">Case Study 1: Fine-Tuning BERT for Sentiment Analysis</h3>
<p>The Bidirectional Encoder Representations from Transformers (BERT) model has become a cornerstone in natural language processing (NLP) tasks due to its ability to understand context in text. However, when applied to a specific task like sentiment analysis, BERT requires fine-tuning to deliver optimal results. In this case study, we explore how fine-tuning BERT on a sentiment analysis dataset, such as the IMDb reviews dataset, can improve its ability to classify text as positive or negative.</p>
<p>In the code example above, we demonstrate the process of fine-tuning a BERT model for sentiment analysis. We define a custom dataset class to handle text and label pairs, tokenize the input text, and set up a Trainer from the <code>transformers</code> library to manage the training process. This fine-tuning allows BERT to adjust its parameters specifically for sentiment analysis, thereby enhancing its predictive accuracy on this task.</p>
</section>
<section id="case-study-2-fine-tuning-gpt-3-for-custom-text-generation" class="level3">
<h3 class="anchored" data-anchor-id="case-study-2-fine-tuning-gpt-3-for-custom-text-generation">Case Study 2: Fine-Tuning GPT-3 for Custom Text Generation</h3>
<p>Generative Pre-trained Transformer 3 (GPT-3) is renowned for its ability to generate human-like text. However, when tasked with generating text in a specific domain, such as legal or medical documents, fine-tuning becomes essential. This case study explores how fine-tuning GPT-3 on a specialized corpus can tailor its outputs to meet domain-specific requirements.</p>
<p>Fine-tuning GPT-3 involves using a smaller, domain-specific dataset to adjust the model weights subtly, ensuring that the generated text aligns with the desired style and content. For example, a legal firm might fine-tune GPT-3 using a corpus of legal documents to generate drafts of contracts or legal summaries. This process involves using techniques like few-shot learning, where only a small number of examples are needed to guide the model’s output effectively.</p>
<p>The pseudo-code above outlines the process of fine-tuning GPT-3 using the OpenAI API. By providing a set of examples and specifying the task, users can guide the model to produce text that closely follows the desired format and content style. This approach highlights the flexibility and power of fine-tuning in customizing AI models to fit specific use cases.</p>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>These case studies underscore the importance and effectiveness of fine-tuning in adapting pre-trained models to specific tasks and domains. By strategically addressing the challenges of fine-tuning, such as selecting appropriate datasets and managing training parameters, organizations can harness the full potential of AI models to deliver tailored, high-performance solutions.</p>
</section>
</section>
<section id="future-trends-in-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="future-trends-in-fine-tuning">Future Trends in Fine-Tuning</h2>
<p>As we look towards the future of fine-tuning in AI, several trends are emerging that promise to enhance the capabilities and efficiency of machine learning models. Fine-tuning, which involves adapting a pre-trained model to a specific task, is becoming increasingly sophisticated, driven by advancements in computational power, algorithmic innovation, and the proliferation of diverse datasets. This section explores these trends, providing insights into how they are shaping the landscape of AI solutions.</p>
<p>One significant trend is the development of more efficient fine-tuning methods that reduce the computational cost and time associated with adapting large models. Techniques such as parameter-efficient fine-tuning (PEFT) are gaining traction. PEFT methods, like LoRA (Low-Rank Adaptation), focus on adjusting only a small subset of model parameters, rather than the entire model, thus significantly reducing the resources required for fine-tuning.</p>
<p>Another trend is the use of self-supervised learning to enhance fine-tuning. Self-supervised learning enables models to learn useful representations from unlabeled data, which can then be fine-tuned with minimal labeled examples. This approach is particularly valuable in domains where labeled data is scarce or expensive to obtain. By leveraging large amounts of unlabeled data, models can achieve better performance with fewer labeled examples during the fine-tuning phase.</p>
<p>In addition to these technical advancements, there is a growing emphasis on ethical considerations in fine-tuning. As AI solutions become more integrated into decision-making processes, ensuring that models are fair, transparent, and unbiased is crucial. Techniques such as adversarial debiasing and fairness-aware fine-tuning are being developed to address these challenges, ensuring that AI systems do not perpetuate or exacerbate existing biases.</p>
<p>Finally, the integration of domain-specific knowledge into fine-tuning processes is becoming more prevalent. By incorporating expert knowledge or domain-specific constraints, models can be fine-tuned to perform more effectively in specialized fields such as healthcare, finance, or legal services. This trend highlights the importance of interdisciplinary collaboration in the development of strategic AI solutions.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./05-retrieval-augmented-generation.html" class="pagination-link" aria-label="Retrieval Augmented Generation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Retrieval Augmented Generation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./07-agents.html" class="pagination-link" aria-label="Agents">
        <span class="nav-page-text"><span class="chapter-title">Agents</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>